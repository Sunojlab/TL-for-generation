{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Fine-tuning of regressor.ipynb","provenance":[{"file_id":"1ev4kfNuWzOKYqJ-kaQqlGYsHzQukfIIk","timestamp":1639205740235},{"file_id":"1hoGKL0lpJGnb0HVWhQ2ACmu5Uo2UNSuu","timestamp":1634722013930}],"collapsed_sections":[],"authorship_tag":"ABX9TyP6o0FoiVDBcKbf91L4c7c2"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JCsVEVa7J9kb"},"source":["## Fine-tuning\n","- This notebook contains code for the fine-tuning of target-task regressor using weights of pre-trained language model \n","- The code is adapted from https://github.com/XinhaoLi74/MolPMoFiT/blob/master/notebooks/04_QSAR_Regression.ipynb"]},{"cell_type":"markdown","metadata":{"id":"FaI3OCkzKaiA"},"source":["#### Install RDKit on Google colaboratory"]},{"cell_type":"code","metadata":{"id":"pOPy7EGzw7g4"},"source":["%%bash\n","add-apt-repository ppa:ubuntu-toolchain-r/test\n","apt-get update --fix-missing\n","apt-get dist-upgrade\n","wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","chmod +x Miniconda3-latest-Linux-x86_64.sh\n","./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n","conda config --set always_yes yes --set changeps1 no\n","conda install -q -y -c conda-forge python=3.7\n","conda install -q -y -c conda-forge rdkit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NmmZlMTMw9Dx"},"source":["import sys\n","sys.path.append('/usr/local/lib/python3.7/site-packages/')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lx-CJc9tKihg"},"source":["Import the important libraries"]},{"cell_type":"code","metadata":{"id":"iyTyIHjdHLNs"},"source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","\n","from rdkit import Chem\n","from rdkit.Chem import Draw\n","from rdkit.Chem.Draw import IPythonConsole\n","from rdkit import RDLogger \n","RDLogger.DisableLog('rdApp.*') # switch off RDKit warning messages\n","\n","from sklearn.model_selection import train_test_split\n","\n","from fastai import *\n","from fastai.text import *\n","from fastai.vision import *\n","\n","import numpy as np\n","import threading\n","import random\n","from sklearn.utils import shuffle "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kEC4EkeLKrsC"},"source":["Set the seed value"]},{"cell_type":"code","metadata":{"id":"TUnv94uOKs7w"},"source":["def random_seed(seed_value, use_cuda):\n","    np.random.seed(seed_value) # cpu vars\n","    torch.manual_seed(seed_value) # cpu  vars\n","    random.seed(seed_value) # Python\n","    if use_cuda: \n","        torch.cuda.manual_seed(seed_value)\n","        torch.cuda.manual_seed_all(seed_value) # gpu vars\n","        torch.backends.cudnn.deterministic = True  #needed\n","        torch.backends.cudnn.benchmark = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pTbSO2vAKzny"},"source":["# Data\n","Mount Google Drive to Google Colab to access the google drive files "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EF_7I25AK08_","executionInfo":{"status":"ok","timestamp":1639813504793,"user_tz":-330,"elapsed":17531,"user":{"displayName":"Sukriti Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUZMkxVpkZQVO63HmhXZupvA11gxiYV6MCwj_Mmg=s64","userId":"07984768194642529599"}},"outputId":"e074ad2f-563f-4670-c6f8-7ff4d1ef54eb"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"7geVIc-7K3dl"},"source":["# Create a path to save the results\n","\n","data_path = Path('/content/gdrive/My Drive/results')\n","name = 'regressor'\n","path = data_path/name\n","path.mkdir(exist_ok=True, parents=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f4M2u9IdK8c_","executionInfo":{"status":"ok","timestamp":1639813506006,"user_tz":-330,"elapsed":564,"user":{"displayName":"Sukriti Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUZMkxVpkZQVO63HmhXZupvA11gxiYV6MCwj_Mmg=s64","userId":"07984768194642529599"}},"outputId":"0ecb934c-d4fc-4454-d6fc-dc7d23405357"},"source":["data = pd.read_csv('/content/gdrive/My Drive/data/740-reactions-yield.csv')\n","print('Dataset:', data.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset: (740, 2)\n"]}]},{"cell_type":"markdown","metadata":{"id":"iM4rjINkLTrY"},"source":["### Target task regressor fine-tuning on target task LM"]},{"cell_type":"markdown","metadata":{"id":"1wE9jf1YLYZG"},"source":["Train-validation-test splits\n","\n","- Split the data into train-validation-test sets\n","- Validation set is used for hyperparameter tuning\n","- Test set is used for the final performance evaluation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"elnrUwadLX25","executionInfo":{"status":"ok","timestamp":1639813554046,"user_tz":-330,"elapsed":391,"user":{"displayName":"Sukriti Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUZMkxVpkZQVO63HmhXZupvA11gxiYV6MCwj_Mmg=s64","userId":"07984768194642529599"}},"outputId":"f25ff03f-9eaa-49b8-ef07-92b6784853bb"},"source":["random_seed(1234, True)\n","\n","train_ , test = train_test_split(data, test_size=0.20, random_state=0)\n","train, valid = train_test_split(train_, test_size=0.108, random_state=0)\n","\n","print(train.shape)\n","print(test.shape)\n","print(valid.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(738, 2)\n","(2, 2)\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZwKLQ-6HLjJZ"},"source":["### SMILES augmentation for regression task"]},{"cell_type":"markdown","metadata":{"id":"OLbtFL0BLt2M"},"source":["- For the regression task, a gaussian noise (with mean zero and standard deviation, σg_noise) is added to the labels of the augmented SMILES during the training\n","- The number of augmented SMILES and σg_noise is tuned on the validation set"]},{"cell_type":"code","metadata":{"id":"QnMjAIUrHT9M"},"source":["def randomize_smiles(smiles):\n","    m = Chem.MolFromSmiles(smiles)\n","    ans = list(range(m.GetNumAtoms()))\n","    np.random.shuffle(ans)\n","    nm = Chem.RenumberAtoms(m,ans)\n","    return Chem.MolToSmiles(nm, canonical=False, isomericSmiles=True, kekuleSmiles=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PmkPCc0eLoal"},"source":["def ee_smiles_augmentation(df, N_rounds, noise):\n","    '''\n","    noise: add gaussion noise to the label\n","    '''\n","    dist_aug = {col_name: [] for col_name in df}\n","\n","    for i in range(df.shape[0]):\n","        for j in range(N_rounds):\n","            dist_aug['smiles'].append(randomize_smiles(df.iloc[i].smiles))\n","            dist_aug['yield'].append(df.iloc[i]['yield'] + np.random.normal(0,noise))\n","    df_aug = pd.DataFrame.from_dict(dist_aug)\n","    df_aug = df_aug.append(df, ignore_index=True)\n","    return df_aug.drop_duplicates('smiles')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yh5O6OG0I2r1","executionInfo":{"status":"ok","timestamp":1639813724340,"user_tz":-330,"elapsed":69787,"user":{"displayName":"Sukriti Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUZMkxVpkZQVO63HmhXZupvA11gxiYV6MCwj_Mmg=s64","userId":"07984768194642529599"}},"outputId":"48ddbb44-57df-432f-bef4-e63b3c3796f2"},"source":["random_seed(1234, True)\n","\n","train_aug = ee_smiles_augmentation(train, 100, noise=0.0)\n","print(\"Train_aug: \", train_aug.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train_aug:  (74531, 2)\n"]}]},{"cell_type":"markdown","metadata":{"id":"zEc8kZScMFYz"},"source":["### Data pre-processing"]},{"cell_type":"markdown","metadata":{"id":"OTE_dUSDMLsT"},"source":["Define a custom tokenizer"]},{"cell_type":"code","metadata":{"id":"1XMdhvKTMHtT"},"source":["# Don't include the defalut specific token of fastai, only keep the padding token\n","BOS,EOS,FLD,UNK,PAD = 'xxbos','xxeos','xxfld','xxunk','xxpad'\n","TK_MAJ,TK_UP,TK_REP,TK_WREP = 'xxmaj','xxup','xxrep','xxwrep'\n","defaults.text_spec_tok = [PAD]\n","\n","special_tokens = ['[BOS]', '[C@H]', '[C@@H]','[C@]', '[C@@]','[C-]','[C+]', '[c-]', '[c+]','[cH-]',\n","                   '[nH]', '[N+]', '[N-]', '[n+]', '[n-]' '[NH+]', '[NH2+]',\n","                   '[O-]', '[S+]', '[s+]', '[S-]', '[O+]', '[SH]', '[B-]','[BH2-]', '[BH3-]','[b-]',\n","                   '[PH]','[P+]', '[I+]', \n","                  '[Si]','[SiH2]', '[Se]','[SeH]', '[se]', '[Se+]', '[se+]','[te]','[te+]', '[Te]']\n","\n","class MolTokenizer(BaseTokenizer):\n","    def __init__(self, lang = 'en', special_tokens = special_tokens):\n","        self.lang = lang\n","        self.special_tokens = special_tokens\n","        \n","    def tokenizer(self, smiles):\n","        # add specific token '[BOS]' to represetences the start of SMILES\n","        smiles = '[BOS]' + smiles\n","        regex = '(\\[[^\\[\\]]{1,10}\\])'\n","        char_list = re.split(regex, smiles)\n","        tokens = []\n","        \n","        if self.special_tokens:\n","            for char in char_list:\n","                if char.startswith('['):\n","                    if char in special_tokens:\n","                        tokens.append(str(char))\n","                    else:\n","                        tokens.append('[UNK]')\n","                else:\n","                    chars = [unit for unit in char]\n","                    [tokens.append(i) for i in chars]                    \n","        \n","        if not self.special_tokens:\n","            for char in char_list:\n","                if char.startswith('['):\n","                    tokens.append(str(char))\n","                else:\n","                    chars = [unit for unit in char]\n","                    [tokens.append(i) for i in chars]\n","                \n","        #fix the 'Br' be splited into 'B' and 'r'\n","        if 'B' in tokens:\n","            for index, tok in enumerate(tokens):\n","                if tok == 'B':\n","                    if index < len(tokens)-1: # make sure 'B' is not the last character\n","                        if tokens[index+1] == 'r':\n","                            tokens[index: index+2] = [reduce(lambda i, j: i + j, tokens[index : index+2])]\n","        \n","        #fix the 'Cl' be splited into 'C' and 'l'\n","        if 'l' in tokens:\n","            for index, tok in enumerate(tokens):\n","                if tok == 'l':\n","                    if tokens[index-1] == 'C':\n","                            tokens[index-1: index+1] = [reduce(lambda i, j: i + j, tokens[index-1 : index+1])]\n","        return tokens    \n","    \n","    def add_special_cases(self, toks):\n","        pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EJq4PNusMRkE"},"source":["bs = 128\n","tok = Tokenizer(partial(MolTokenizer, special_tokens = special_tokens), n_cpus=6, pre_rules=[], post_rules=[])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G4ZC6MOTJCDv"},"source":["Adpot the encoder of the pre-trained LM according to the target dataset\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"imddL80mN7kg","executionInfo":{"status":"ok","timestamp":1639813729987,"user_tz":-330,"elapsed":5652,"user":{"displayName":"Sukriti Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUZMkxVpkZQVO63HmhXZupvA11gxiYV6MCwj_Mmg=s64","userId":"07984768194642529599"}},"outputId":"90c50072-0e4a-4995-cbd1-911105ecdfd7"},"source":["np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning) \n","random_seed(1234, True)\n","\n","lm_vocab = TextLMDataBunch.from_df(path, train_aug, valid, bs=bs, tokenizer=tok, \n","                              chunksize=50000, text_cols=0, label_cols=1, max_vocab=60000, include_bos=False, min_freq=1, num_workers=0)\n","print(f'Vocab Size: {len(lm_vocab.vocab.itos)}')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Vocab Size: 32\n"]}]},{"cell_type":"code","metadata":{"id":"Esr8ehTFN-FG"},"source":["pretrained_model_path = Path('/content/gdrive/My Drive/results/MSPM/models')\n","pretrained_fnames = ['pre-trained_wt', 'pre-trained_vocab']\n","fnames = [pretrained_model_path/f'{fn}.{ext}' for fn,ext in zip(pretrained_fnames, ['pth', 'pkl'])]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GeKcUMrOOBGc"},"source":["random_seed(1234, True)\n","\n","lm_learner = language_model_learner(lm_vocab, AWD_LSTM, drop_mult=0.2, pretrained=False)\n","lm_learner = lm_learner.load_pretrained(*fnames)\n","lm_learner.freeze()\n","lm_learner.save_encoder(f'lm_encoder')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wRwAirrxOEXF"},"source":["Create a text databunch for regression:\n","\n","- It takes as input the train and validation data\n","- Pass the vocab of the pre-trained LM as defined in the previous step\n","- Specify the column containing text data and output\n","- Define the batch size according to the GPU memory available\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"4IpahKD-ODRF","executionInfo":{"status":"ok","timestamp":1639813757024,"user_tz":-330,"elapsed":12154,"user":{"displayName":"Sukriti Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUZMkxVpkZQVO63HmhXZupvA11gxiYV6MCwj_Mmg=s64","userId":"07984768194642529599"}},"outputId":"290480da-1e88-4c65-a2a8-ab9798915103"},"source":["random_seed(1234, True)\n","\n","data_clas = TextClasDataBunch.from_df(path, train_aug, valid, bs=bs, tokenizer=tok, \n","                                          chunksize=50000, text_cols='smiles',label_cols='yield', \n","                                          vocab=lm_vocab.vocab, max_vocab=60000, include_bos=False, min_freq=1, num_workers=0)\n","\n","print(f'Vocab Size: {len(data_clas.vocab.itos)}')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Vocab Size: 32\n"]}]},{"cell_type":"markdown","metadata":{"id":"Kk2kZ9V5OUoy"},"source":["### Training the regression model"]},{"cell_type":"markdown","metadata":{"id":"X0Vs1CL4NRkm"},"source":["Create a learner for regression:\n","\n","- Pass the databunch\n","- Load the encoder of the pre-trained LM\n","- The drop_mult hyperparameter can be tuned\n","- The model is evaluated using RMSE and R-squared value as error metric"]},{"cell_type":"code","metadata":{"id":"70eCKGwwOX13"},"source":["random_seed(1234, True)\n","\n","reg_learner = text_classifier_learner(data_clas, AWD_LSTM, pretrained=False, drop_mult=0.0, metrics = [r2_score, rmse])\n","reg_learner.load_encoder(f'lm_encoder')\n","reg_learner.freeze()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gPSxFKFr3uwH"},"source":["# Model architecture\n","reg_learner.model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iGt4qRezNnEZ"},"source":["The regressor is fine-tuned all at once without any frozen weights (i.e., no gradual unfreezing)"]},{"cell_type":"code","metadata":{"id":"UG90CfeKNpmZ"},"source":["random_seed(1234, True)\n","\n","reg_learner.unfreeze()\n","reg_learner.fit_one_cycle(25, 1e-3, moms=(0.8,0.7))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BOUGPj9sneFw"},"source":["Save the trained learner. It is then later used for prediction on test set"]},{"cell_type":"code","metadata":{"id":"1hVnvsU9Oj2z"},"source":["split_id = 0\n","reg_learner.save(f'{split_id}_reg')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2mv-aCNtOmwO"},"source":["#### Evaluation on the Test Set"]},{"cell_type":"code","metadata":{"id":"WPfIu6o4OpCV"},"source":["def test_smiles_augmentation(df, N_rounds):\n","    dist_aug = {col_name: [] for col_name in df}\n","\n","    for i in range(df.shape[0]):\n","        for j in range(N_rounds):\n","            dist_aug['smiles'].append(randomize_smiles(df.iloc[i].smiles))\n","            dist_aug['yield'].append(df.iloc[i]['yield'])\n","    df_aug = pd.DataFrame.from_dict(dist_aug)\n","    \n","    return pd.DataFrame.from_dict(dist_aug)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SAllppdDe8B8"},"source":["random_seed(1234, True)\n","\n","tok_new = TokenizeProcessor(tokenizer=tok, chunksize=50000, include_bos=False)\n","num_new = NumericalizeProcessor(vocab=lm_vocab.vocab, max_vocab=60000, min_freq=1) \n","\n","ee_data = pd.read_csv('/content/gdrive/My Drive/data/740-reactions-yield.csv')\n","\n","train_ , test_ = train_test_split(ee_data, test_size=0.2, random_state=0)\n","train , test = train_test_split(ee_data, test_size=0.2, random_state= 0)\n","\n","train_.insert(2, 'valid', False)\n","test_.insert(2, 'valid', True)\n","df = pd.concat([train_, test_])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"cW0fwQlVZywq","executionInfo":{"status":"ok","timestamp":1639817901930,"user_tz":-330,"elapsed":20995,"user":{"displayName":"Sukriti Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUZMkxVpkZQVO63HmhXZupvA11gxiYV6MCwj_Mmg=s64","userId":"07984768194642529599"}},"outputId":"46983ee8-1a18-43e2-8630-37ae7673c2a8"},"source":["random_seed(1234, True)\n","\n","preds = []\n","\n","# Randomized SMILES Predictions\n","for i in range(4):\n","    np.random.seed(12*i)\n","    test_aug = test_smiles_augmentation(test, 1)\n","    \n","    #model\n","    \n","    test_aug.insert(2, 'valid', True)\n","    df_aug = pd.concat([train, test_aug])\n","    test_db = (TextList.from_df(df_aug, path, cols='smiles', processor=[tok_new, num_new]).split_from_df(col='valid').label_from_df(cols='yield', label_cls=FloatList).databunch(bs=128))\n","    \n","    learner = text_classifier_learner(test_db, AWD_LSTM, config=None, pretrained=False, drop_mult=0.0, metrics = [r2_score, rmse])\n","    \n","    learner.load(f'{split_id}_reg'); \n","  \n","    #get predictions\n","    pred,lbl = learner.get_preds(ordered=True)\n","    \n","    preds.append(pred)\n","\n","# Canonical SMILES Predictions\n","\n","test_db = (TextList.from_df(df, path, cols='smiles', processor=[tok_new, num_new]).split_from_df(col='valid').label_from_df(cols='yield', label_cls=FloatList).databunch(bs=128))\n","\n","learner = text_classifier_learner(test_db, AWD_LSTM, config=None, pretrained=False, drop_mult=0.0, metrics = [r2_score, rmse])\n","\n","learner.load(f'{split_id}_reg');\n","\n","\n","#get predictions\n","pred_canonical,lbl = learner.get_preds(ordered=True)\n","    \n","preds.append(pred_canonical)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"cin_ygfT9Plp"},"source":["The test set performance is evaluated using the predictions based on the canonical SMILES as well as that employing test-time augmentation"]},{"cell_type":"code","metadata":{"id":"OTe8N2HmOu7Q"},"source":["print('Test Set (Canonical)')\n","print('RMSE:', root_mean_squared_error(pred_canonical,lbl))\n","print('MAE:', mean_absolute_error(pred_canonical,lbl))\n","print('R2:', r2_score(pred_canonical,lbl))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yyvqaP6-Ox-I"},"source":["avg_preds = sum(preds)/len(preds)\n","#print('\\n')\n","print('Test Set (Average)')\n","print('RMSE:', root_mean_squared_error(avg_preds,lbl))\n","print('MAE:', mean_absolute_error(avg_preds,lbl))\n","print('R2:', r2_score(avg_preds,lbl))"],"execution_count":null,"outputs":[]}]}