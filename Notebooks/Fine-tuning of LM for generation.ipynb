{"cells":[{"cell_type":"markdown","source":["## Fine-tuning of language model (LM) and molecule generation\n","- This notebook contains code for the fine-tuning of target-task LM using pre-trained weights of the pre-trained LM \n","- The code is adapted from https://github.com/marcossantanaioc/De_novo_design_SARSCOV2"],"metadata":{"id":"EuVVRqkCxJny"}},{"cell_type":"markdown","source":["#### Install RDKit on Google colaboratory"],"metadata":{"id":"JRIco4bNxwr-"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"El_6e98J3TAA"},"outputs":[],"source":["%%bash\n","add-apt-repository ppa:ubuntu-toolchain-r/test\n","apt-get update --fix-missing\n","apt-get dist-upgrade\n","wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","chmod +x Miniconda3-latest-Linux-x86_64.sh\n","./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n","conda config --set always_yes yes --set changeps1 no\n","conda install -q -y -c conda-forge python=3.7\n","conda install -q -y -c conda-forge rdkit\n","#conda install -q -y -c openbabel openbabel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Hxctu2-B3bz6"},"outputs":[],"source":["import sys\n","sys.path.append('/usr/local/lib/python3.7/site-packages/')"]},{"cell_type":"markdown","metadata":{"id":"2T3gvdHlEhwa"},"source":["Import the important libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqu7kzBQEKkV"},"outputs":[],"source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","import time\n","import pandas as pd\n","import sys\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from torch.utils.data import WeightedRandomSampler\n","import random\n","import numpy as np\n","from google.colab import drive\n","\n","from fastai.callbacks import *\n","from fastai.text import *\n","from fastai.metrics import *\n","\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPQGZLBcEKlM"},"outputs":[],"source":["from rdkit import Chem\n","from rdkit import rdBase\n","from rdkit.Chem import Draw, AllChem\n","from IPython.display import display,Image, SVG\n","from rdkit.Chem import rdmolops\n","rdBase.DisableLog('rdApp.error')"]},{"cell_type":"markdown","source":["Set the seed value"],"metadata":{"id":"5h0NN2lsx_ew"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Ock3WMvwIyA"},"outputs":[],"source":["def random_seed(seed_value, use_cuda):\n","    np.random.seed(seed_value) # cpu vars\n","    torch.manual_seed(seed_value) # cpu  vars\n","    random.seed(seed_value) # Python\n","    if use_cuda: \n","        torch.cuda.manual_seed(seed_value)\n","        torch.cuda.manual_seed_all(seed_value) # gpu vars\n","        torch.backends.cudnn.deterministic = True  #needed\n","        torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","metadata":{"id":"xDZjgSiNEs0o"},"source":["# Data\n","Mount Google Drive to Google Colab to access the google drive files "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19337,"status":"ok","timestamp":1639577763138,"user":{"displayName":"Sukriti Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUZMkxVpkZQVO63HmhXZupvA11gxiYV6MCwj_Mmg=s64","userId":"07984768194642529599"},"user_tz":-330},"id":"mmipEUQCE0zB","outputId":"0902c684-4d9c-4b13-bbf8-4b9b9580f4fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["alc_smiles = pd.read_csv('/content/gdrive/My Drive/data/alcohol-smiles.csv')\n","print('Dataset:', alc_smiles.shape)"],"metadata":{"id":"rMiL1lsHzGqz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8Be_xw8EIQ0"},"outputs":[],"source":["# Create a path to save the results\n","\n","GEN = Path('/content/gdrive/My Drive/results/Generative')\n","GEN.mkdir(parents=True, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l2uoOwfrEybB"},"outputs":[],"source":["GENREG = Path('/content/gdrive/My Drive/results/Generative/Regressor')\n","GENREG.mkdir(parents=True, exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"u1sNSKp5FPg6"},"source":["## Helper functions\n","### Sampling callback"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iU1MTnQhFVpH"},"outputs":[],"source":["def is_valid(smiles):\n","  mol = Chem.MolFromSmiles(smiles)\n","  if mol is not None and mol.GetNumAtoms()>0:\n","      return smiles\n","\n","def uniqueness_score(mols): return set(mols)\n","\n","def novelty_score(mols,ref_mols): \n","    return set.difference(mols,ref_mols)\n","\n","class SamplingCB(LearnerCallback):\n","\n","  '''Sampling callback to generate molecules at the end of each training epoch and compute validity,\n","  novelty and uniqueness.\n","  learn: Learner\n","\n","  source_mols: List -> Reference molecules to compute dataset. \n","\n","  objective_mols: List -> If finetuning is True, the objective is the dataset we are finetuning to.\n","\n","  num_samples: Int -> Number of molecules to generate\n","  '''\n","  _order=-20 # Needs to run before the recorder\n","  def __init__(self,learn:Learner, objective_mols:Collection=None, num_samples:int=100):\n","    super().__init__(learn)\n","    self.num_samples= num_samples\n","    self.max_size = 120\n","    self.temperature = 0.70\n","    self.objective_mols = objective_mols\n","\n","  def on_train_begin(self,**kwargs):\n","    #self.ref_model = load_ref_model()\n","    self.learn.recorder.add_metric_names(['Valid', 'Unique', 'Novel'])\n","\n","  def on_epoch_being(self,**kwargs):\n","    self.objective_mols = random.sample(objective_mols,self.num_samples)\n","\n","  def sampling(self,text:str='', sep:str=''):\n","    \"Vanilla sampling. Return `text` and the `n_words` that come after\"\n","    m = self.learn\n","    m.model.reset()\n","    v = self.learn.data.train_ds.vocab\n","    v_sz = len(v.itos)\n","   # print(v.itos[v_sz-1])\n","    xb,yb = self.learn.data.one_item(text)\n","    new_idx = []\n","    for _ in range(self.max_size):\n","      res = m.pred_batch(batch=(xb,yb))[0][-1]\n","      if self.temperature != 1.: \n","        res.pow_(1 / self.temperature)\n","      idx = torch.multinomial(res, 1).item()\n","      if idx != v_sz-1:              \n","        new_idx.append(idx)\n","        xb = xb.new_tensor([idx])[None]\n","      else:\n","        break\n","    return text + sep + sep.join(v.textify(new_idx, sep=None))\n","\n","  def on_epoch_end(self, last_metrics, **kwargs):\n","    print('Sampling...')\n","    p = [self.sampling().replace('xxbos','').replace('xxeos','').replace('xxunk','').replace('xxpad','') for i in range(0,self.num_samples)]\n","    print('Sample of generated SMILES')\n","    print(p[:5])\n","    val = list(filter(is_valid,p)) # Validity\n","    print(val[0:5])\n","    uniq = uniqueness_score(val) # Uniqueness\n","    novel = novelty_score(uniq, self.objective_mols) # Novelty\n","\n","    return add_metrics(last_metrics, [len(val)/self.num_samples, len(uniq)/self.num_samples, len(novel)/self.num_samples])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lAi7dLnjOFso"},"outputs":[],"source":["def sampling(model,dt,text:str, n_words:int, temperature:float=1., sep:str=' '):\n","  \"Vanilla sampling. Return `text` and the `n_words` that come after\"\n","  model.model.reset()\n","  v = dt.vocab\n","  \n","  xb,yb = dt.one_item(text)\n","  new_idx = []\n","  for _ in range(n_words):\n","    res = model.pred_batch(batch=(xb,yb))[0][-1]\n","\n","    if temperature != 1.: \n","      res.pow_(1 / temperature)\n","    idx = torch.multinomial(res, 1).item()\n","    if idx != len(v.itos)-1:              \n","      new_idx.append(idx)\n","      xb = xb.new_tensor([idx])[None]\n","    else:\n","      break\n","  return text + sep + sep.join(v.textify(new_idx, sep=None))\n","\n","sampling_temperatures = [0.2, 0.5, 0.6, 0.7, 0.75, 0.8, 1.0, 1.2]\n","\n","def validation(model,dt,sampling_temperatures,iterations,samples,ref,maxsize=100):\n","  \n","  '''Vanilla sampling and validation function'''\n","  _validity = np.zeros((iterations,len(sampling_temperatures)))\n","  _novelty = np.zeros((iterations,len(sampling_temperatures)))\n","  _uniqueness = np.zeros((iterations,len(sampling_temperatures)))\n","\n","  for j in range(len(sampling_temperatures)):\n","    temp = sampling_temperatures[j]\n","    print('Temperatures = {}'.format(temp))\n","    for i in range(iterations):\n","      print('Starting iteration {}'.format(i))\n","      p = [sampling(model,dt,text='',n_words=maxsize,sep='',temperature=temp).replace(PAD,'').replace(BOS,'').replace(EOS,'').replace(UNK,'') for i in range(0,samples)]\n","      mols = list(filter(is_valid,p)) # Valid\n","      unq_mols = uniqueness_score(mols) # Uniqueness # Unique\n","      novel_mols = novelty_score(unq_mols, ref) # Novel\n","\n","      _novelty[i,j] = len(novel_mols)/samples*100\n","      _uniqueness[i,j] = len(unq_mols)/samples*100\n","      _validity[i,j] = len(mols)/samples*100\n","\n","      print('Iteration {} ended'.format(i))\n","    print('----------------------------------')\n","  return _validity, _novelty, _uniqueness, mols, unq_mols, novel_mols"]},{"cell_type":"markdown","metadata":{"id":"BD0p1ccHF1WQ"},"source":["### Data pre-processing"]},{"cell_type":"markdown","source":["Define a custom tokenizer"],"metadata":{"id":"_r2ueR98yiBw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ypSUkZEcF8cY"},"outputs":[],"source":["#@title\n","class MolTokenizer(BaseTokenizer):\n","  ''' Atom-level tokenizer. Splits molecules into individual atoms and special enviroments.\n","  A special enviroment is defined by any elements inside square brackets (e.g., [nH])\n","  '''\n","  def __init__(self, lang:str):\n","    pass\n","  def tokenizer(self,t:str) -> List[str]:\n","    assert type(t) == str\n","    pat = '(\\[.*?\\])' # Find special enviroments (e.g., [CH],[NH] etc)\n","    tokens = []\n","    t = t.replace('Br','L').replace('Cl','X') # Replace halogens\n","    atom_list = re.split(pat,t)\n","    for s in atom_list:\n","      if s.startswith('['):\n","        tokens.append(s)\n","      else:\n","        tokens += [x for x in list(s)]\n","    tokens = [x.replace('L','Br').replace('X','Cl') for x in tokens] # Decode halogens\n","    return [BOS] + tokens + [EOS]# + [PAD for i in range(133-len(tokens))]\n","\n","class Create_Vocab(object):\n","  '''Tokenize and create vocabulary of atoms in SMILES strings'''\n","  def __init__(self,smiles):\n","    self.smiles = smiles\n","\n","  def tokenize(self):\n","    k = MolTokenizer\n","    tok = Tokenizer(k,pre_rules=[],post_rules=[])\n","    tokens = tok.process_all(self.smiles)\n","\n","    unique_tokens = [UNK, PAD] + sorted(list({y for x in tokens for y in x}))\n","    vocab = Vocab(itos=unique_tokens)\n","    \n","    return unique_tokens, vocab"]},{"cell_type":"markdown","metadata":{"id":"wg4PxybdHkoW"},"source":["#### SMILES augmentation for language model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"79f-hUKIJUph"},"outputs":[],"source":["def randomize_smiles(smiles):\n","    m = Chem.MolFromSmiles(smiles)\n","    ans = list(range(m.GetNumAtoms()))\n","    np.random.shuffle(ans)\n","    nm = Chem.RenumberAtoms(m,ans)\n","    return Chem.MolToSmiles(nm, canonical=False, isomericSmiles=True, kekuleSmiles=False)\n","\n","def lm_smiles_augmentation(df, N_rounds):\n","    \n","    dist_aug = {col_name: [] for col_name in df}\n","\n","    for i in range(df.shape[0]):\n","        for j in range(N_rounds):\n","            dist_aug['smiles'].append(randomize_smiles(df.iloc[i].smiles))\n","    df_aug = pd.DataFrame.from_dict(dist_aug)\n","    df_aug = df_aug.append(df, ignore_index=True)\n","    return df_aug.drop_duplicates('smiles')"]},{"cell_type":"markdown","source":["The randomized SMILES are used for data augmentation. The number of augmented SMILES can be passed an arguement to the lm_smiles_augmentation function"],"metadata":{"id":"ToGJrhAYzlmB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kV675JIbJYTf"},"outputs":[],"source":["random_seed(1234, True)\n","\n","alc_smiles_aug = ee_smiles_augmentation(alc_smiles, 110)\n","print(len(alc_smiles_aug))"]},{"cell_type":"markdown","source":["Create a text databunch for language modeling:\n","\n","- It takes SMILES as input\n","- Pass the custom tokenizer defined in the previous step\n","- Specify the column containing text data\n","- Define the batch size according to the GPU memory available"],"metadata":{"id":"JLXiL3931RTA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YP516btCIBW3"},"outputs":[],"source":["random_seed(1234, True)\n","\n","vocab_list = Create_Vocab(list(alc_smiles_aug.smiles))\n","unique_tokens,vocab = vocab_list.tokenize()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WP-F6xwFIPxo"},"outputs":[],"source":["random_seed(1234, True)\n","\n","tokenizer = Tokenizer(MolTokenizer,pre_rules=[],post_rules=[],special_cases=[PAD,BOS,EOS,UNK])\n","processors = [TokenizeProcessor(tokenizer=tokenizer, mark_fields=False,include_bos=False), NumericalizeProcessor(vocab=vocab)]\n","src = (TextList.from_df(alc_smiles_aug, path=GEN, cols='smiles', processor=processors).split_by_rand_pct(0.10).label_for_lm())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MFPLXUwYIq3N"},"outputs":[],"source":["random_seed(1234, True)\n","\n","data_fn = src.databunch()\n","data_fn.show_batch()"]},{"cell_type":"markdown","source":["## Fine-tuning the target task language model "],"metadata":{"id":"5W2T96iqJ7o4"}},{"cell_type":"markdown","source":["Load the pre-trained weights and vocabulary"],"metadata":{"id":"LI-VM3emJ9T_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6cDGfqybJF-9"},"outputs":[],"source":["pretrained_model_path = Path('/content/gdrive/My Drive/results/MSPM/models')\n","pretrained_fnames = ['pre-trained_wt', 'pre-trained_vocab']\n","fnames = [pretrained_model_path/f'{fn}.{ext}' for fn,ext in zip(pretrained_fnames, ['pth', 'pkl'])]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTtO8YE1D9ct"},"outputs":[],"source":["#reference dataset\n","obj_ref = list(set(alc_smiles.smiles))\n","print(len(obj_ref))"]},{"cell_type":"markdown","source":["Create a learner for language modeling:\n","\n","- Initialize the learner with the pre-trained weights\n","- Pass the text databunch loaded in the previous step\n","- Drop_mult is a hyperparameter that can be tuned\n","- Accuracy is the metric used for model evaluation"],"metadata":{"id":"Qrh8P2-bKKRp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJz6g8lZl9UZ"},"outputs":[],"source":["random_seed(1234, True)\n","\n","learn_fn = language_model_learner(data_fn, AWD_LSTM, pretrained=False, drop_mult=0.4, metrics=[accuracy, error_rate], callback_fns=[partial(CSVLogger,append=True)]).load_pretrained(*fnames)\n","learn_fn.freeze()"]},{"cell_type":"markdown","source":["Train the model using fit_one_cycle in three steps using gradual unfreezing:\n","\n","- For the first step, the weights of the LSTM layers are kept frozen and the rest of the model is trained.\n","- In the second step, the weight of last LSTM is unfrozen\n","- In the third step, all layers are unfrozen so that the LSTM layers can be fine-tuned\n","- Number of epochs and learning rate are the two hyperparameters that can be tuned here"],"metadata":{"id":"uyldRMDIKUoP"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":660},"executionInfo":{"elapsed":54545,"status":"ok","timestamp":1639578062025,"user":{"displayName":"Sukriti Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUZMkxVpkZQVO63HmhXZupvA11gxiYV6MCwj_Mmg=s64","userId":"07984768194642529599"},"user_tz":-330},"id":"YcgzpCFTl9Vi","outputId":"617e24ae-4212-41da-e7b6-8d00d3db7295"},"outputs":[{"data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>error_rate</th>\n","      <th>Valid</th>\n","      <th>Unique</th>\n","      <th>Novel</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>1.189117</td>\n","      <td>1.041965</td>\n","      <td>0.710491</td>\n","      <td>0.289509</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>00:19</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.885585</td>\n","      <td>0.689171</td>\n","      <td>0.782738</td>\n","      <td>0.217262</td>\n","      <td>0.770000</td>\n","      <td>0.770000</td>\n","      <td>0.770000</td>\n","      <td>00:08</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.724809</td>\n","      <td>0.619877</td>\n","      <td>0.804613</td>\n","      <td>0.195387</td>\n","      <td>0.890000</td>\n","      <td>0.890000</td>\n","      <td>0.870000</td>\n","      <td>00:07</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.640362</td>\n","      <td>0.607313</td>\n","      <td>0.807069</td>\n","      <td>0.192932</td>\n","      <td>0.930000</td>\n","      <td>0.930000</td>\n","      <td>0.930000</td>\n","      <td>00:07</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.591198</td>\n","      <td>0.594575</td>\n","      <td>0.810565</td>\n","      <td>0.189435</td>\n","      <td>0.940000</td>\n","      <td>0.940000</td>\n","      <td>0.940000</td>\n","      <td>00:07</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Sampling...\n","Sample of generated SMILES\n","[')CC2(CCCC2)CC1=O)C(=O)OC(C)(C)CCCCOC1OCCO1)[C@@H](O)[C@H](O)CO[C@H]1O[C@H](CO)[C@@H](O)[C@H](O)[C@@H]1OC(=O)CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC', ')=C(C(OC)=O)C(C)=N1CN1CCCCC1C2=O)C(=O)OCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC', ')ccccc1)=O)OCCN(CC)CCOC(=O)C(C)Oc1ccccc1[N+]([O-])=O)c1c([N+](=O)[O-])cc(OC)cc1[N+]([O-])=Oc1c(OC)ccc(C(=O)OC)c1OC(=O)CCCCCCCCCCCCCCCCCCCC', ')cc(C)ccc1OC(C)OC(OC(C)(C)C)=O)C[C@H]1[C@H](O)C(C)(C)Oc2ccc(C(=O)O)cc212CCC2=C(C)CCC/C(C)=C/COC(=O)CC(C)CCCC(C)CCCC(C)CCCC(C)CCC', ')nc(C)n(CCO)c1ncn2C(C)=O)(C)OC(C1CCCCC1)=O)(C)COC(=O)CCC(O)=O[C@@H]1[C@@H]2[C@@H](C(COC(C)=O)=CO[C@H]2O)[C@H]2[C@@H]1[C@]1(C)CCC[C@@](COC(C)=O)(C)[C@H]1CC2=ONC']\n","[]\n","Better model found at epoch 0 with accuracy value: 0.7104911208152771.\n","Sampling...\n","Sample of generated SMILES\n","['=[N+](CCCCC)[O-])[C@H]1[C@H](O)CO[C@H]1CO', '=C1C(OC)=CC(O)(C=C)C=C1', 'C(CCCCC)(O)CC(OC)=O', 'c1c(OC)ccc(/C=C2\\\\C(OC)=C(OC)C(=O)O2)c1', 'c1cccc(C(n2c(C)c(CCO)c(C)n2)c2ccccc2)c1']\n","['C(CCCCC)(O)CC(OC)=O', 'c1c(OC)ccc(/C=C2\\\\C(OC)=C(OC)C(=O)O2)c1', 'c1cccc(C(n2c(C)c(CCO)c(C)n2)c2ccccc2)c1', 'N(CCCC(O)=O)c1ccc(C(O)=O)cc1', 'C(C(=O)OC)OC(=O)CC(=O)OCCC(C)CCCC(CO)=C']\n","Better model found at epoch 1 with accuracy value: 0.7827381491661072.\n","Sampling...\n","Sample of generated SMILES\n","['[C@@]12(C)OO[C@@]34[C@H]([C@H](C)CC[C@H]3[C@H](C)CC[C@H]4[C@H]1C)OO2', 'C(c1ccccc1)(c1ccccc1)(c1ccccc1)N', 'c1cccc(C2C(C(OCC)=O)=C(COC(c3ccccc3)=O)OC(N)=C2C(OCC)=O)c1', 'c1cccc(C[C@H](NC(OC(C)(C)C)=O)C(O)CO)c1', '[N+](=O)C(C(C)O)O']\n","['[C@@]12(C)OO[C@@]34[C@H]([C@H](C)CC[C@H]3[C@H](C)CC[C@H]4[C@H]1C)OO2', 'C(c1ccccc1)(c1ccccc1)(c1ccccc1)N', 'c1cccc(C2C(C(OCC)=O)=C(COC(c3ccccc3)=O)OC(N)=C2C(OCC)=O)c1', 'c1cccc(C[C@H](NC(OC(C)(C)C)=O)C(O)CO)c1', '[N+](=O)C(C(C)O)O']\n","Better model found at epoch 2 with accuracy value: 0.8046131134033203.\n","Sampling...\n","Sample of generated SMILES\n","['C1C[C@H](O)CC[C@H]1N1CCN(Cc2ccccc2)CC1', 'O1C(C)(C)O[C@H]2[C@H](OC)[C@@H](OC)C(O)O[C@H]12', '=[N+]=N[C@@H]1C2[C@@](CO)(CCC2O)C2C(O)C(O)C3C(CCC4=CC(=O)C=C[C@@]34C)C2C1', 'c1(C)cc(-c2ccccc2)n2nc(C(=O)OCC(=O)c3ccc(Cl)cc3)nc2n1', 'COC(C1=C(C)OC(O)=C(C(OC)=O)C1c1ccc([N+](=O)[O-])cc1)=O']\n","['C1C[C@H](O)CC[C@H]1N1CCN(Cc2ccccc2)CC1', 'O1C(C)(C)O[C@H]2[C@H](OC)[C@@H](OC)C(O)O[C@H]12', 'c1(C)cc(-c2ccccc2)n2nc(C(=O)OCC(=O)c3ccc(Cl)cc3)nc2n1', 'COC(C1=C(C)OC(O)=C(C(OC)=O)C1c1ccc([N+](=O)[O-])cc1)=O', 'c1cccc2n(C(=O)c3ccccc3)c(C)c(CCO)c12']\n","Better model found at epoch 3 with accuracy value: 0.8070685267448425.\n","Sampling...\n","Sample of generated SMILES\n","['c12c(ncnc1)n(CCC)cn2', 'CC(C)(O)COC(=O)c1ccccc1', '[N+](=O)c1cc(Cl)c(C(OCC(=O)OC(C)(C)C)=O)cc1', '[N+](c1c(CO)c(Cl)cc(OC)c1OC)=O', 'O[C@H]1CN(CCCC)C2(CCCC2)C1']\n","['c12c(ncnc1)n(CCC)cn2', 'CC(C)(O)COC(=O)c1ccccc1', '[N+](=O)c1cc(Cl)c(C(OCC(=O)OC(C)(C)C)=O)cc1', '[N+](c1c(CO)c(Cl)cc(OC)c1OC)=O', 'O[C@H]1CN(CCCC)C2(CCCC2)C1']\n","Better model found at epoch 4 with accuracy value: 0.8105654716491699.\n"]}],"source":["random_seed(1234, True)\n","\n","learn_fn.fit_one_cycle(5, 1e-1, moms=(0.8,0.7), callbacks=[SamplingCB(learn_fn, num_samples=100, objective_mols=obj_ref),\n","                                   SaveModelCallback(learn_fn, every='improvement',monitor='accuracy', name='bestmodel')])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":726},"executionInfo":{"elapsed":46396,"status":"ok","timestamp":1639578108410,"user":{"displayName":"Sukriti Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUZMkxVpkZQVO63HmhXZupvA11gxiYV6MCwj_Mmg=s64","userId":"07984768194642529599"},"user_tz":-330},"id":"Hhv5swW8mcxF","outputId":"8d74fb54-a02b-42a9-c254-d271840792af"},"outputs":[{"data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>error_rate</th>\n","      <th>Valid</th>\n","      <th>Unique</th>\n","      <th>Novel</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.457638</td>\n","      <td>0.516757</td>\n","      <td>0.838095</td>\n","      <td>0.161905</td>\n","      <td>0.970000</td>\n","      <td>0.970000</td>\n","      <td>0.860000</td>\n","      <td>00:07</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.396397</td>\n","      <td>0.453073</td>\n","      <td>0.855208</td>\n","      <td>0.144792</td>\n","      <td>1.000000</td>\n","      <td>0.980000</td>\n","      <td>0.670000</td>\n","      <td>00:07</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.355367</td>\n","      <td>0.435677</td>\n","      <td>0.855208</td>\n","      <td>0.144792</td>\n","      <td>0.990000</td>\n","      <td>0.960000</td>\n","      <td>0.600000</td>\n","      <td>00:08</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.326964</td>\n","      <td>0.425345</td>\n","      <td>0.859747</td>\n","      <td>0.140253</td>\n","      <td>1.000000</td>\n","      <td>0.980000</td>\n","      <td>0.470000</td>\n","      <td>00:07</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.308238</td>\n","      <td>0.421426</td>\n","      <td>0.858929</td>\n","      <td>0.141071</td>\n","      <td>1.000000</td>\n","      <td>0.960000</td>\n","      <td>0.510000</td>\n","      <td>00:07</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.289998</td>\n","      <td>0.421951</td>\n","      <td>0.859524</td>\n","      <td>0.140476</td>\n","      <td>1.000000</td>\n","      <td>0.980000</td>\n","      <td>0.460000</td>\n","      <td>00:07</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Sampling...\n","Sample of generated SMILES\n","['OC(C1CCC(O)CC1)(c1ccccc1)c1ccccc1', 'CCN(CC(=O)OC)C(=O)OC1(CO)Cc1ccccc1', 'C1[C@@H](O)[C@H]2[C@H](O)C[C@H]3[C@@](C)([C@H]2CC1)CC[C@H]1[C@]3(C)CC[C@H](O)C1', 'OC(C)CCC(O)CCCCCCC=C', 'CCOC(=O)c1c(CO)n(C)c2ccc(OCCCC(O)(Cn3cncn3)c3ccc(F)cc3F)cc12']\n","['OC(C1CCC(O)CC1)(c1ccccc1)c1ccccc1', 'C1[C@@H](O)[C@H]2[C@H](O)C[C@H]3[C@@](C)([C@H]2CC1)CC[C@H]1[C@]3(C)CC[C@H](O)C1', 'OC(C)CCC(O)CCCCCCC=C', 'CCOC(=O)c1c(CO)n(C)c2ccc(OCCCC(O)(Cn3cncn3)c3ccc(F)cc3F)cc12', 'C1C2CCC(CC1O)N2C(=O)OC(C)(C)C']\n","Better model found at epoch 0 with accuracy value: 0.8380951881408691.\n","Sampling...\n","Sample of generated SMILES\n","['C1CC(O)CC2=CC[C@H]3[C@H]4CC=C(c5cccnc5)[C@@]4(C)CC[C@@H]3[C@@]12C', 'C(CCC)N(CC(c1cc(Cl)cc2c1-c1c(cc(Cl)cc1)/C2=C/c1ccc(Cl)cc1)O)CCCC', 'C(CCCC)N(CCCCC)CCCO', 'c1ccccc1C(n1c2c(nc1)c(N(Cc1ccccc1)Cc1ccccc1)ncn2)c1ccccc1', 'C(Cc1ccccc1)C(C)O']\n","['C1CC(O)CC2=CC[C@H]3[C@H]4CC=C(c5cccnc5)[C@@]4(C)CC[C@@H]3[C@@]12C', 'C(CCC)N(CC(c1cc(Cl)cc2c1-c1c(cc(Cl)cc1)/C2=C/c1ccc(Cl)cc1)O)CCCC', 'C(CCCC)N(CCCCC)CCCO', 'c1ccccc1C(n1c2c(nc1)c(N(Cc1ccccc1)Cc1ccccc1)ncn2)c1ccccc1', 'C(Cc1ccccc1)C(C)O']\n","Better model found at epoch 1 with accuracy value: 0.8552083373069763.\n","Sampling...\n","Sample of generated SMILES\n","['C1=C2[C@@](C)([C@H]3C(=O)C[C@@]4(C)[C@H]([C@@H]3CC2)CC[C@]4(C(=O)CO)O)CC1', 'c1cc(C(c2ccccc2)(c2ccccc2)N[C@H](C(=O)OC)CO)ccc1', 'C1[C@]2(C)C(c3cccnc3)=CC[C@H]2[C@@H]2CCC3=CC(=O)C=C[C@]3(C)[C@H]2C1', 'CC1(C)O[C@@H]([C@H]2O[C@@H]3OC(C)(C)O[C@@H]3[C@@H]2O)CO1', 'n1(C(=O)c2ccc(Cl)cc2)c(C)c(CCO)c2c1ccc(OC)c2']\n","['C1=C2[C@@](C)([C@H]3C(=O)C[C@@]4(C)[C@H]([C@@H]3CC2)CC[C@]4(C(=O)CO)O)CC1', 'c1cc(C(c2ccccc2)(c2ccccc2)N[C@H](C(=O)OC)CO)ccc1', 'C1[C@]2(C)C(c3cccnc3)=CC[C@H]2[C@@H]2CCC3=CC(=O)C=C[C@]3(C)[C@H]2C1', 'CC1(C)O[C@@H]([C@H]2O[C@@H]3OC(C)(C)O[C@@H]3[C@@H]2O)CO1', 'n1(C(=O)c2ccc(Cl)cc2)c(C)c(CCO)c2c1ccc(OC)c2']\n","Sampling...\n","Sample of generated SMILES\n","['c1ccc(C(c2ccccc2)(n2nnnc2-c2ccccc2-c2ccc(Cn3c(CO)c(Cl)nc3CCCC)cc2)c2ccccc2)cc1', 'c1c(ccc(c1)CO)[N+](=O)[O-]', 'C(CCC)CCCC(O)C=Cc1c(/N=N/c2ccc([N+](=O)[O-])cc2Cl)ccc(N(CCO)CC)c1', 'c1c(Cl)ccc(/C=C2/c3cc(Cl)cc(C(O)CN(CCCC)CCCC)c3-c3ccc(Cl)cc32)c1', 'OCCCc1cnc2n(c1)ncn2']\n","['c1ccc(C(c2ccccc2)(n2nnnc2-c2ccccc2-c2ccc(Cn3c(CO)c(Cl)nc3CCCC)cc2)c2ccccc2)cc1', 'c1c(ccc(c1)CO)[N+](=O)[O-]', 'C(CCC)CCCC(O)C=Cc1c(/N=N/c2ccc([N+](=O)[O-])cc2Cl)ccc(N(CCO)CC)c1', 'c1c(Cl)ccc(/C=C2/c3cc(Cl)cc(C(O)CN(CCCC)CCCC)c3-c3ccc(Cl)cc32)c1', 'OCCCc1cnc2n(c1)ncn2']\n","Better model found at epoch 3 with accuracy value: 0.8597469925880432.\n","Sampling...\n","Sample of generated SMILES\n","['C(=C(\\\\C)CCC=C(C)C)\\\\CC/C(C)=C/CO', 'C(O)(CCCCn1c(=O)c2n(C)cnc2n(C)c1=O)C', 'C1CCCN1[C@@H](C)[C@@H](c1ccccc1)O', 'C(C(O)C)CCCn1c(=O)n(C)c2ncn(C)c2c1=O', 'O=C(C)O[C@H]1[C@@H]2[C@H](OC1)[C@H](O)CO2']\n","['C(=C(\\\\C)CCC=C(C)C)\\\\CC/C(C)=C/CO', 'C(O)(CCCCn1c(=O)c2n(C)cnc2n(C)c1=O)C', 'C1CCCN1[C@@H](C)[C@@H](c1ccccc1)O', 'C(C(O)C)CCCn1c(=O)n(C)c2ncn(C)c2c1=O', 'O=C(C)O[C@H]1[C@@H]2[C@H](OC1)[C@H](O)CO2']\n","Sampling...\n","Sample of generated SMILES\n","['C(OC)(=O)[C@@H]1N(C(=O)OC(C)(C)C)C[C@@H](O)C1', '[C@@H]12[C@H](C(=O)C[C@]3(C)[C@H]1CC[C@@]3(C(CO)=O)O)[C@]1(C)C(=CC(=O)C=C1)CC2', 'c1cc(/N=N/c2c(Cl)cc([N+](=O)[O-])cc2)ccc1N(CCO)CC', 'C(C(C)O)CCOc1ccccc1', 'C(CC)CN(CCCC)CC(O)c1c2c(cc(Cl)c1)/C(=C\\\\c1ccc(Cl)cc1)c1c-2ccc(Cl)c1']\n","['C(OC)(=O)[C@@H]1N(C(=O)OC(C)(C)C)C[C@@H](O)C1', '[C@@H]12[C@H](C(=O)C[C@]3(C)[C@H]1CC[C@@]3(C(CO)=O)O)[C@]1(C)C(=CC(=O)C=C1)CC2', 'c1cc(/N=N/c2c(Cl)cc([N+](=O)[O-])cc2)ccc1N(CCO)CC', 'C(C(C)O)CCOc1ccccc1', 'C(CC)CN(CCCC)CC(O)c1c2c(cc(Cl)c1)/C(=C\\\\c1ccc(Cl)cc1)c1c-2ccc(Cl)c1']\n"]}],"source":["random_seed(1234, True)\n","\n","learn_fn.freeze_to(-2)\n","\n","learn_fn.fit_one_cycle(6, 1e-2, moms=(0.8,0.7), callbacks=[SamplingCB(learn_fn, num_samples=100, objective_mols=obj_ref),\n","                                  SaveModelCallback(learn_fn, every='improvement', monitor='accuracy', name='bestmodel')])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":709},"executionInfo":{"elapsed":51044,"status":"ok","timestamp":1639578160917,"user":{"displayName":"Sukriti Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUZMkxVpkZQVO63HmhXZupvA11gxiYV6MCwj_Mmg=s64","userId":"07984768194642529599"},"user_tz":-330},"id":"JBi9M3mwmczD","outputId":"caf82f0f-e911-4db7-a30c-7b9bc4055ab2"},"outputs":[{"data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>error_rate</th>\n","      <th>Valid</th>\n","      <th>Unique</th>\n","      <th>Novel</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.263676</td>\n","      <td>0.429610</td>\n","      <td>0.860193</td>\n","      <td>0.139807</td>\n","      <td>1.000000</td>\n","      <td>0.980000</td>\n","      <td>0.450000</td>\n","      <td>00:07</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.263043</td>\n","      <td>0.413682</td>\n","      <td>0.862351</td>\n","      <td>0.137649</td>\n","      <td>0.990000</td>\n","      <td>0.980000</td>\n","      <td>0.460000</td>\n","      <td>00:07</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.259629</td>\n","      <td>0.430949</td>\n","      <td>0.859152</td>\n","      <td>0.140848</td>\n","      <td>1.000000</td>\n","      <td>0.980000</td>\n","      <td>0.390000</td>\n","      <td>00:08</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.257053</td>\n","      <td>0.434126</td>\n","      <td>0.857292</td>\n","      <td>0.142708</td>\n","      <td>1.000000</td>\n","      <td>0.970000</td>\n","      <td>0.400000</td>\n","      <td>00:08</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.257199</td>\n","      <td>0.427920</td>\n","      <td>0.857366</td>\n","      <td>0.142634</td>\n","      <td>0.990000</td>\n","      <td>0.960000</td>\n","      <td>0.360000</td>\n","      <td>00:07</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.252817</td>\n","      <td>0.433349</td>\n","      <td>0.859077</td>\n","      <td>0.140923</td>\n","      <td>0.990000</td>\n","      <td>0.940000</td>\n","      <td>0.330000</td>\n","      <td>00:08</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Sampling...\n","Sample of generated SMILES\n","['C(=C1\\\\c2cc(Cl)cc(C(O)CN(CCCC)CCCC)c2-c2ccc(Cl)cc21)\\\\c1ccc(Cl)cc1', 'c1ccc(OCC(O)C)cc1', 'C1C[C@@]2(C)OO[C@]34[C@H](O[C@H](O)[C@@H](C)C3CC[C@@H](C)[C@@H]4C1)O2', 'c1(-c2oc(CCCO)nc2-c2ccccc2)ccccc1', 'C(OC)(=O)[C@@H]1N(C(=O)OC(C)(C)C)C[C@@H](O)C1']\n","['C(=C1\\\\c2cc(Cl)cc(C(O)CN(CCCC)CCCC)c2-c2ccc(Cl)cc21)\\\\c1ccc(Cl)cc1', 'c1ccc(OCC(O)C)cc1', 'C1C[C@@]2(C)OO[C@]34[C@H](O[C@H](O)[C@@H](C)C3CC[C@@H](C)[C@@H]4C1)O2', 'c1(-c2oc(CCCO)nc2-c2ccccc2)ccccc1', 'C(OC)(=O)[C@@H]1N(C(=O)OC(C)(C)C)C[C@@H](O)C1']\n","Better model found at epoch 0 with accuracy value: 0.8601934313774109.\n","Sampling...\n","Sample of generated SMILES\n","['C(C)CN(S(c1ccc(CO)cc1)(=O)=O)CCC', 'c1ccc(CCCCO)cc1', 'c1ccccc1C(c1ccccc1)(N[C@@H](CO)C(=O)OC)c1ccccc1', 'CCCCN(CCCC)CC(O)c1c2c(cc(Cl)c1)/C(=C\\\\c1ccc(Cl)cc1)c1c-2ccc(Cl)c1', 'C1(C)(C)O[C@@H]([C@@H]2O[C@H]3OC(C)(C)O[C@@H]3[C@@H]2O)CO1']\n","['C(C)CN(S(c1ccc(CO)cc1)(=O)=O)CCC', 'c1ccc(CCCCO)cc1', 'c1ccccc1C(c1ccccc1)(N[C@@H](CO)C(=O)OC)c1ccccc1', 'CCCCN(CCCC)CC(O)c1c2c(cc(Cl)c1)/C(=C\\\\c1ccc(Cl)cc1)c1c-2ccc(Cl)c1', 'C1(C)(C)O[C@@H]([C@@H]2O[C@H]3OC(C)(C)O[C@@H]3[C@@H]2O)CO1']\n","Better model found at epoch 1 with accuracy value: 0.8623511791229248.\n","Sampling...\n","Sample of generated SMILES\n","['O=C(CO)[C@@]1(O)CC[C@H]2[C@H]3CCC4=CC(=O)C=C[C@]4(C)[C@H]3C(=O)C[C@]21C', 'O=C(C)O[C@H]1[C@H]2OC[C@@H](O)[C@H]2OC1', 'OC1CCC(N2C(=O)c3c(cccc3)C2=O)CC1', 'C(CN(CCCC)CC(O)c1c2c(cc(Cl)c1)/C(=C\\\\c1ccc(Cl)cc1)c1c-2ccc(Cl)c1)CC', 'C(C)(O)CCCCn1c(=O)n(C)c2c(n(C)cn2)c1=O']\n","['O=C(CO)[C@@]1(O)CC[C@H]2[C@H]3CCC4=CC(=O)C=C[C@]4(C)[C@H]3C(=O)C[C@]21C', 'O=C(C)O[C@H]1[C@H]2OC[C@@H](O)[C@H]2OC1', 'OC1CCC(N2C(=O)c3c(cccc3)C2=O)CC1', 'C(CN(CCCC)CC(O)c1c2c(cc(Cl)c1)/C(=C\\\\c1ccc(Cl)cc1)c1c-2ccc(Cl)c1)CC', 'C(C)(O)CCCCn1c(=O)n(C)c2c(n(C)cn2)c1=O']\n","Sampling...\n","Sample of generated SMILES\n","['c1c(C(N[C@@H](CO)C(=O)OC)(c2ccccc2)c2ccccc2)cccc1', 'C1(O)CC2N(C(OC(C)(C)C)=O)C(CC2)C1', 'O=[N+]([O-])c1cnc(C)n1CCO', 'C(CCN(CCCC)CC(c1c2c(cc(Cl)c1)/C(=C\\\\c1ccc(Cl)cc1)c1c-2ccc(Cl)c1)O)C', 'c1c(F)ccc(-c2cc(CO)no2)c1']\n","['c1c(C(N[C@@H](CO)C(=O)OC)(c2ccccc2)c2ccccc2)cccc1', 'C1(O)CC2N(C(OC(C)(C)C)=O)C(CC2)C1', 'O=[N+]([O-])c1cnc(C)n1CCO', 'C(CCN(CCCC)CC(c1c2c(cc(Cl)c1)/C(=C\\\\c1ccc(Cl)cc1)c1c-2ccc(Cl)c1)O)C', 'c1c(F)ccc(-c2cc(CO)no2)c1']\n","Sampling...\n","Sample of generated SMILES\n","['[C@H]12[C@]34[C@@H](CC[C@@](C)(O[C@H]3O[C@H](O)[C@@H]1C)OO4)[C@H](C)CC2', 'c1(C(c2ccccc2)(c2ccccc2)n2nnnc2-c2ccccc2-c2ccc(Cn3c(CCCC)nc(Cl)c3CO)cc2)ccccc1', '[C@@H]12OC(C)(C)O[C@H]1O[C@H]([C@@H]1OC(C)(C)OC1)[C@H]2O', 'C(CCO)c1cn2ncnc2nc1', 'C1(=O)C[C@]2(C)[C@@](O)(C(=O)CO)CC[C@H]2[C@H]2[C@H]1[C@@]1(C)C=CC(=O)C=C1CC2']\n","['[C@H]12[C@]34[C@@H](CC[C@@](C)(O[C@H]3O[C@H](O)[C@@H]1C)OO4)[C@H](C)CC2', 'c1(C(c2ccccc2)(c2ccccc2)n2nnnc2-c2ccccc2-c2ccc(Cn3c(CCCC)nc(Cl)c3CO)cc2)ccccc1', '[C@@H]12OC(C)(C)O[C@H]1O[C@H]([C@@H]1OC(C)(C)OC1)[C@H]2O', 'C(CCO)c1cn2ncnc2nc1', 'C1(=O)C[C@]2(C)[C@@](O)(C(=O)CO)CC[C@H]2[C@H]2[C@H]1[C@@]1(C)C=CC(=O)C=C1CC2']\n","Sampling...\n","Sample of generated SMILES\n","['C1(O)CC2N(C(=O)OC(C)(C)C)C(CC2)C1', 'C1CCCN1[C@H]([C@@H](c1ccccc1)O)C', 'c1cccc(C(c2ccccc2)(c2ccccc2)N[C@H](C(OC)=O)CO)c1', 'C(CC(O)(C)C)c1ccccc1', 'C1C2[C@]34OO[C@@](C)(O[C@H]3O[C@H](O)[C@@H]2C)CC[C@H]4[C@H](C)C1']\n","['C1(O)CC2N(C(=O)OC(C)(C)C)C(CC2)C1', 'C1CCCN1[C@H]([C@@H](c1ccccc1)O)C', 'c1cccc(C(c2ccccc2)(c2ccccc2)N[C@H](C(OC)=O)CO)c1', 'C(CC(O)(C)C)c1ccccc1', 'C1C2[C@]34OO[C@@](C)(O[C@H]3O[C@H](O)[C@@H]2C)CC[C@H]4[C@H](C)C1']\n"]}],"source":["random_seed(1234, True)\n","\n","learn_fn.unfreeze()\n","\n","learn_fn.fit_one_cycle(6, 1e-3, moms=(0.8,0.7), callbacks=[SamplingCB(learn_fn, num_samples=100, objective_mols=obj_ref),\n","                                   SaveModelCallback(learn_fn, every='improvement', \n","                                                     monitor='accuracy', name='bestmodel')])"]},{"cell_type":"markdown","source":["Save the model"],"metadata":{"id":"IQYJeAJaK4O4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UfLgcu4-RypP"},"outputs":[],"source":["learn_fn.save_encoder('finetuned_encoder_alc')"]},{"cell_type":"markdown","source":["#### Validate the fine-tuned model in terms of validity, uniqueness, and novelty"],"metadata":{"id":"aMAlF_tBLWG-"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":822,"status":"ok","timestamp":1634622921639,"user":{"displayName":"Sukriti Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUZMkxVpkZQVO63HmhXZupvA11gxiYV6MCwj_Mmg=s64","userId":"07984768194642529599"},"user_tz":-330},"id":"yZCHnUA8JrjN","outputId":"9b7bb128-5d02-4f12-a709-a2e700c6bf48"},"outputs":[{"data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[0.41006887, tensor(0.8413), tensor(0.1587)]"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["learn_fn.validate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v3eFE7BxaNNp"},"outputs":[],"source":["random_seed(1234, True)\n","\n","validity, novelty, uniqueness, mols, unq_mols, novel_mols = validation(learn_fn, data_fn, sampling_temperatures, 1, 500, ref=obj_ref)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mkjWeM2oa3Fg"},"outputs":[],"source":["val_df = pd.DataFrame(validity, columns=['Temp_{}'.format(i) for i in sampling_temperatures])\n","nov_df = pd.DataFrame(novelty, columns=['Temp_{}'.format(i) for i in sampling_temperatures])\n","unq_df = pd.DataFrame(uniqueness, columns=['Temp_{}'.format(i) for i in sampling_temperatures])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MZ3vrijlqGup"},"outputs":[],"source":["pd.Series(list(novel_mols)).to_csv(\"nov_alc.csv\", index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Fine-tuning of LM for generation.ipynb","provenance":[{"file_id":"1n0dX8Jf2Uua7GjBckCkpmQEZh2uXwoZx","timestamp":1644476914609}],"authorship_tag":"ABX9TyM3Ju/2bsUAepfn6Msxet/F"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}